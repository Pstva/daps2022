{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8147436",
   "metadata": {},
   "source": [
    "# 1. Causal inference: Data Simulation and Average Treatment Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43188a63",
   "metadata": {},
   "source": [
    "Very useful book: https://users.aalto.fi/~ave/ROS.pdf. Lectures and seminars are based on the chapters 18-21."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aff555c",
   "metadata": {},
   "source": [
    "## Simulating Data\n",
    "\n",
    "Plan is to look at how we can create:\n",
    "+ samples from normal distributions\n",
    "+ several variables from normal distributions with specified correlation\n",
    "+ dataset with 2 correlated variables with specified treatment effect\n",
    "+ vector z for random treatment assignment with specified probability to being assigned to the treatment\n",
    "+ imitate population with different stratas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba39a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdd93da",
   "metadata": {},
   "source": [
    "Sample from normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fca08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "# here - mean=0, sd=1, size of the sample=10\n",
    "x = np.random.normal(loc=0.0, scale=1.0, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e883ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b86a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.normal(loc=0.0, scale=1.0, size=1000)\n",
    "plt.hist(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cf5c3d",
   "metadata": {},
   "source": [
    "**Creating several variables with specified correlation**\n",
    "\n",
    "\n",
    "Pearson's correlation: \n",
    "\n",
    "$$\\rho(X, Y) = \\frac{\\text{cov}(X, Y)}{\\sigma_x \\sigma_y}$$\n",
    "\n",
    "so, $$\\text{cov}(X, Y) = \\rho(X, Y) \\sigma_x \\sigma_y$$\n",
    "\n",
    "For creating multivariate Normal distribution $X \\sim N(\\mu, \\Sigma)$ we need the vector of means $\\mu$ (mean value for each variable) and covariance matrix $\\Sigma$. For example, for 3-dimensional Multivariate Normal distribution covariance matrix would look like:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\text{cov}(x_1, x_1) & \\text{cov}(x_1, x_2) & \\text{cov}(x_1, x_3)\\\\\n",
    "\\text{cov}(x_2, x_1) & \\text{cov}(x_2, x_2) & \\text{cov}(x_2, x_3)\\\\\n",
    "\\text{cov}(x_3, x_1) & \\text{cov}(x_3, x_2) & \\text{cov}(x_3, x_3)\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "So, if we want to create, for example, 3 variables $X_1, X_2, Y_2$ with pair-wise correlations $\\rho(X_1, X_2) = a$, $\\rho(X_1, X_3) = b$, $\\rho(X_2, X_3) = c$, then we need to create the following covariance matrix:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\sigma_{x1} \\sigma_{x1} & a \\sigma_{x1} \\sigma_{x2} & b \\sigma_{x1} \\sigma_{x3}\\\\\n",
    "a \\sigma_{x1} \\sigma_{x2} & \\sigma_{x2} \\sigma_{x2} & c \\sigma_{x2} \\sigma_{x3})\\\\\n",
    "b \\sigma_{x1} \\sigma_{x3} & c \\sigma_{x2} \\sigma_{x3} & \\sigma_{x3} \\sigma_{x3}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "(note: this matrix is symmetric and $ \\text{cov}(x_i, x_j) =  \\text{cov}(x_j, x_i)$, as well as $ \\rho(x_i, x_j) =  \\rho(x_j, x_i)$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6817742",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "Let's create samle of size 10 with 3 variables $X_1, X_2, X_3$ with means [2, 100, 10] and standard deviations [1, 5.5, 2.3] with the following correlations:\n",
    "\n",
    "$\\rho(X_1, X_2) = 0.3$, $\\rho(X_1, X_3) = 0.8$, $\\rho(X_2, X_3) = 0.45$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd31266",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.array([2, 100, 10])\n",
    "sds = np.array([1, 5.5, 2.3])\n",
    "\n",
    "corr_matrix = np.array([\n",
    "    [1, 0.3, 0.8],\n",
    "    [0.3, 1, 0.45],\n",
    "    [0.8, 0.45, 1]])\n",
    "\n",
    "sds_mult = np.array([\n",
    "    [sds[0] * sds[0], sds[0] * sds[1], sds[0] * sds[2]],\n",
    "    [sds[1] * sds[0], sds[1] * sds[1], sds[1] * sds[2]],\n",
    "    [sds[2] * sds[0], sds[2] * sds[1], sds[2] * sds[2]]])\n",
    "\n",
    "# more accurate: sds_mult = np.outer(sds, sds)\n",
    "\n",
    "cov_matrix = corr_matrix * sds_mult\n",
    "data = np.random.multivariate_normal(means, cov_matrix, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307ff4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking correlations\n",
    "\n",
    "np.corrcoef(data, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3f061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling more observations\n",
    "data = np.random.multivariate_normal(means, cov_matrix, size=1000)\n",
    "\n",
    "#checking correlations\n",
    "print(np.corrcoef(data, rowvar=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7e04c8",
   "metadata": {},
   "source": [
    "**More automatic way to create covariance matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862b389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for creating dataset with correlated variables from normal distribution\n",
    "\n",
    "def create_correlated_variables(num_variables, num_samples, means, sds, corr_matrix):\n",
    "    assert means.shape[0] == num_variables, f\"There should be {num_samples} mean values for num_samples={num_samples}, got {means.shape[0]}\"\n",
    "    assert sds.shape[0] == num_variables, f\"There should be {num_samples} sds values for num_samples={num_samples}, got {sds.shape[0]}\"\n",
    "    assert corr_matrix.shape[0] == corr_matrix.shape[1] == num_variables, f\"Size of the corr_matrix should be ({num_variables},{num_variables}), got {corr_matrix.shape}\"\n",
    "    assert (corr_matrix <= 1).all() and (corr_matrix >= -1).all(), \"All values in corr_matrix should be between -1 and 1\"\n",
    "    \n",
    "    sds_mult = np.outer(sds, sds)\n",
    "    cov_matrix = corr_matrix * sds_mult\n",
    "    \n",
    "    return np.random.multivariate_normal(means, cov_matrix, size=num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed55a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usage example\n",
    "means = np.array([2, 100, 10])\n",
    "sds = np.array([1, 5.5, 2.3])\n",
    "\n",
    "corr_matrix = np.array([\n",
    "    [1, 0.3, 0.8],\n",
    "    [0.3, 1, 0.45],\n",
    "    [0.8, 0.45, 1]])\n",
    "x = create_correlated_variables(3, 10000, means, sds, corr_matrix)\n",
    "np.corrcoef(x, rowvar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8c569b",
   "metadata": {},
   "source": [
    "**Creating dataset with 2 correlated variables with specified treatment effect**\n",
    "\n",
    "simulating a randomized experiment - imagine we have 2 groups of people - treated and controlled.\n",
    "\n",
    "In this very simple model, the intervention would add 5 points to some scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03332939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y0 and y1 from the same distribution\n",
    "np.random.seed(10)\n",
    "y_if_control = np.random.normal(10, 2, size=10)\n",
    "treatment_effect = 5\n",
    "y_if_treated = np.copy(y_if_control) + treatment_effect\n",
    "\n",
    "data = pd.DataFrame(np.stack([y_if_control, y_if_treated], axis=-1), columns = ['y0', 'y1'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3407a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or we can create y0 and y1 from different correlated distributions\n",
    "\n",
    "means = np.array([10, 10])\n",
    "sds = np.array([2, 2])\n",
    "corr_matrix = np.array([\n",
    "    [1, 0.8],\n",
    "    [0.8, 1]\n",
    "])\n",
    "\n",
    "data1 = create_correlated_variables(2, 10, means, sds, corr_matrix)\n",
    "\n",
    "\n",
    "treatment_effect = 5\n",
    "\n",
    "# data[:, 0] - controlled, y0\n",
    "data1[:, 1] += treatment_effect # treated, y1\n",
    "\n",
    "data1 = pd.DataFrame(data, columns = ['y0', 'y1'])\n",
    "\n",
    "\n",
    "# or we can just add some noise from normal distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da20f2c",
   "metadata": {},
   "source": [
    "**random treatment assignment: completely randomized experiment**\n",
    "\n",
    "in a completely randomized experiment, treatments assigned just randomly. Let's simulate this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f588e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating treatment assignment randomly from bernoulli dostribution\n",
    "# assigning treatment to each person with probability 0.5 (this probability may differ)\n",
    "z = np.random.binomial(1, 0.5, size=len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6118115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e30187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['z'] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e035589",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c0a96",
   "metadata": {},
   "source": [
    "**imitating population groups**\n",
    "\n",
    "Now, let's imagine that we also have Age column in our data. \n",
    "\n",
    "Let's generate new data with this column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5065b221",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100\n",
    "\n",
    "\n",
    "# age column\n",
    "age = np.random.normal(40, 10, sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5e6447",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f058cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting age column to int\n",
    "age = age.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71848dbb",
   "metadata": {},
   "source": [
    "we will have 3 groups/blocks of people (based on their age), and there will be treatment effects in different blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614e38f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(age), np.max(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5977e56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(age < 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc30e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 groups - [19-30, 30-45, 45-60]\n",
    "# this if my random division into groups, in real research such things are done accorring to some theory/knowledge\n",
    "age_groups = np.copy(age)\n",
    "age_groups[age < 30] = 1\n",
    "age_groups[(age >= 30)*(age < 45)] = 2\n",
    "age_groups[age >= 45] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1306603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "age_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d7d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_age_groups = pd.DataFrame(age_groups, columns=['age_group'])\n",
    "data_age_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b70e867",
   "metadata": {},
   "source": [
    "Let's also again generate the potential outcome. But now, let's assume that treatment effect depends on the age group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d58ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "y_if_control = np.random.normal(10, 2, size=sample_size)\n",
    "y_if_treated = np.copy(y_if_control)\n",
    "\n",
    "data_age_groups['y0'] = y_if_control # y if control\n",
    "data_age_groups['y1'] = y_if_treated # y if treated, but its not final version, we would add TE here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d891adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_age_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ff6d27",
   "metadata": {},
   "source": [
    "Let's assume that TE(treatment effect) for the 1st group is -2, for the 2nd is 5, and for the third is 10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d6f07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_age_groups['y1'] = data_age_groups.apply(lambda x: x.y1 - 2 if x.age_group==1 \n",
    "                                              else x.y1 + 5 if x.age_group==2 \n",
    "                                              else x.y1 + 10, \n",
    "                                              axis=1)\n",
    "# you can do the same thing but on raw numpy arrays just by indexing  with age_groups array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f032db8a",
   "metadata": {},
   "source": [
    "and, just for now, let's again simulate completely randomized experiment - assign treatments randomly without conditioning on blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260c1c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning treatment to each person with probability 0.3\n",
    "z = np.random.binomial(1, 0.3, size=len(data_age_groups))\n",
    "data_age_groups['z'] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6be6817",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_age_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bda1560",
   "metadata": {},
   "source": [
    "**example of rerandomization**\n",
    "\n",
    "In the previous step, we assigned treatment just randomly across all the participants.\n",
    "\n",
    "Now let's rerandomize our experiment. Let's assign the treatment depending ob the age group with the following probabilities:\n",
    "\n",
    "+ 1 group, prob=0.2\n",
    "+ 2 group, prob=0.4\n",
    "+ 3 group, prob=0.6\n",
    "\n",
    "In other words, we group our participant into blocks depending on their age, and then assign treatment for each group with different probailities. Probability of being assigned to the treatment is higher for older people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded17744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_treatment(age_group):\n",
    "    if age_group == 1:\n",
    "        return np.random.binomial(1, 0.2)\n",
    "    if age_group == 2:\n",
    "        return np.random.binomial(1, 0.4)\n",
    "    if age_group == 3:\n",
    "        return np.random.binomial(1, 0.6)\n",
    "\n",
    "\n",
    "data_age_groups['z_new'] = data_age_groups['age_group'].apply(assign_treatment)\n",
    "\n",
    "data_age_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1401ad2d",
   "metadata": {},
   "source": [
    "## Little summary: data simulation\n",
    "\n",
    "When simulating data for such task we need to think about:\n",
    "    \n",
    "1. **Treatment effect**\n",
    "\n",
    "Simulating y0 and y1 (how are they connected? from one distribution/correlated variables). TE can be equal to all the people, or depend on a group/some covariate.\n",
    "\n",
    "\n",
    "2. **Treatment assignment (random/randomization in blocks/matched pairs)**\n",
    "\n",
    "Sumulating treatment assignment - creating the vector $z$. We can just randomly assign treatment (saw an example), or we can do it randomly in some groups of people (different probablities of treatment for different groups, here a treatment assignment \n",
    "\n",
    "3. **Covariables/Covariates**\n",
    "\n",
    "Can be discrete (categorical variables, or binned continuous variable)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f3d43",
   "metadata": {},
   "source": [
    "## Average treatment effects\n",
    "\n",
    "In experiments in which only one treatment is applied to each individual, it will not be possible to estimate individual-level causal effects $\\tau_i = y_{i1} - y_{i0}$. \n",
    "\n",
    "The individual causal effect can in general vary by person; hence, any definition of average causal\n",
    "effect will depend on what group of people is being averaged over.\n",
    "\n",
    "Basic types of average causal effects:\n",
    "\n",
    "### Sample average treatment effect (SATE)\n",
    "\n",
    "just averaging over the whole sample\n",
    "\n",
    "$$\\tau_{\\text{SATE}} = \\text{mean}(\\text{y_if_treated}) - \\text{mean}(\\text{y_if_control})$$\n",
    "\n",
    "\n",
    "### Conditional average treatment effect (CATE)\n",
    "\n",
    "We can also calculate the average treatment effect for well-defined subsets such as men , women, or, for instance, 50-year-olds . These estimands are sometimes referred to as conditional\n",
    "average treatment effects (CATEs) and can also take more complicated forms such as expectations\n",
    "(average predictions) from linear regression models.\n",
    "\n",
    "### Population average treatment effect (PATE)\n",
    "\n",
    "similar to SATE, but average treatment effect for the whole population. Obviously, we wouldn't have data for the whole population, but if our study sample is a random sample of the population of interest, then any unbiased estimate of the SATE will also be an unbiased estimate of PATE.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd540f80",
   "metadata": {},
   "source": [
    "Let's calculate SATE and CATE for our simulated data\n",
    "\n",
    "**as a difference in potential outcomes of treated and controlled**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a25546",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = data_age_groups[data_age_groups[\"z\"]==1]['y1'] # y_treated\n",
    "y_c = data_age_groups[data_age_groups[\"z\"]==0]['y0'] # y_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ab9987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SATE TE\n",
    "te_sate = y_t.mean() - y_c.mean() \n",
    "te_sate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eab54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SATE standard error\n",
    "se_te_sate = np.sqrt(np.std(y_t) ** 2 / len(y_t) + np.std(y_c) ** 2 / len(y_c))\n",
    "se_te_sate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565ec8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "?np.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a022f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cate with age groups\n",
    "te_group1 = data_age_groups[data_age_groups[\"z\"]==1][data_age_groups[\"age_group\"]==1]['y1'].mean() - data_age_groups[data_age_groups[\"z\"]==0][data_age_groups[\"age_group\"]==1]['y0'].mean() \n",
    "te_group2 = data_age_groups[data_age_groups[\"z\"]==1][data_age_groups[\"age_group\"]==2]['y1'].mean() - data_age_groups[data_age_groups[\"z\"]==0][data_age_groups[\"age_group\"]==2]['y0'].mean() \n",
    "te_group3 = data_age_groups[data_age_groups[\"z\"]==1][data_age_groups[\"age_group\"]==3]['y1'].mean() - data_age_groups[data_age_groups[\"z\"]==0][data_age_groups[\"age_group\"]==3]['y0'].mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f4ce25",
   "metadata": {},
   "outputs": [],
   "source": [
    "te_group1, te_group2, te_group3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c01576",
   "metadata": {},
   "source": [
    "**with regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46491838",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_age_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cfee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_age_groups['y_real'] = data_age_groups.apply(lambda x: x.y0 if x.z == 0 else x.y1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df997829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# cate\n",
    "m_sate = smf.ols(formula=\"y_real ~ z\", \n",
    "                 data=data_age_groups).fit()\n",
    "m_sate.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cfa55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sate 1\n",
    "m_sate1 = smf.ols(formula=\"y_real ~ z\", \n",
    "                 data=data_age_groups, subset=data_age_groups['age_group']==1).fit()\n",
    "m_sate1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179d8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sate 2\n",
    "m_sate2 = smf.ols(formula=\"y_real ~ z\", \n",
    "                 data=data_age_groups, subset=data_age_groups['age_group']==2).fit()\n",
    "m_sate2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddbdb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sate 3\n",
    "m_sate3 = smf.ols(formula=\"y_real ~ z\", \n",
    "                 data=data_age_groups, subset=data_age_groups['age_group']==3).fit()\n",
    "m_sate3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a137b1b4",
   "metadata": {},
   "source": [
    "### Randomization distribution\n",
    "\n",
    "An unbiased estimate leads us to the right answer on average. Properties of a\n",
    "statistical procedure are reflected in the distribution of the estimate over repeated samples from that\n",
    "population. That is, we can envision taking an infinite number of samples from the population and for\n",
    "each sample calculating the estimate. The distribution of these estimates is the **sampling distribution.**\n",
    "\n",
    "First of all, we can simplify matters by considering all covariates\n",
    "and potential outcomes to be fixed (this is a representation common both to the survey sampling\n",
    "world and the randomization-based inference framework). \n",
    "\n",
    "Then imagine *randomly allocating observations to treatment groups again and again*. *Each new allocation will imply a different set of observed outcomes (since observed outcomes are a function of both potential outcomes and treatment assignment)*. Suppose that with each re-randomization the difference in mean outcomes\n",
    "between the Í treatment and control groups is calculated. The set of these estimates represents the **randomization distribution for this estimate**. If the estimate is unbiased, then the average of all of these estimates (the mean of the randomization distribution) equals the true sample average treatment effect.\n",
    "\n",
    "Let's create loop to create a randomization distribution for an estimate of TE in our data with age groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c013c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 1000\n",
    "\n",
    "te_distr = []\n",
    "\n",
    "for i in range(n_trials):\n",
    "    z = np.random.binomial(1, 0.3, len(data_age_groups))\n",
    "    te = np.mean(data_age_groups.loc[z==1, 'y1']) - np.mean(data_age_groups.loc[z==0, 'y0'])\n",
    "    te_distr.append(te)\n",
    "    \n",
    "plt.hist(te_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95db5665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample average treatment effect and std\n",
    "np.mean(te_distr), np.std(te_distr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffd692f",
   "metadata": {},
   "source": [
    "### Sampling distribution\n",
    "\n",
    "We can try to estimate TE with the different method: \n",
    "+ N times randomly sample some set of our data\n",
    "+ estimate average TE on each set\n",
    "\n",
    "Then we will obtain sampling distibution that contains average TE for each draw. We can take the mean and std of this distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780de01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trials = 1000\n",
    "n_samples = 10\n",
    "\n",
    "te_distr = []\n",
    "\n",
    "for i in range(n_trials):\n",
    "    chosen = np.random.choice(len(data_age_groups), size=n_samples)\n",
    "    data_sampled = data_age_groups.iloc[chosen].copy()\n",
    "    te = np.mean(data_sampled['y1']) - np.mean(data_sampled['y0'])\n",
    "    te_distr.append(te)\n",
    "    \n",
    "plt.hist(te_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07a3e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample average treatment effect and std\n",
    "np.mean(te_distr), np.std(te_distr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1767e2",
   "metadata": {},
   "source": [
    "## Little summary: calculating average treatment effects\n",
    "\n",
    "There are two main methods to calculate TE (sate or cate or TE for particular group):\n",
    "+ as a difference between potential outcomes between groups\n",
    "+ with linear regression\n",
    "\n",
    "We can also estimate TE with sampling distribution (sample random part of data, calculate TE, repeat N times)\n",
    "\n",
    "Randomization distribution works only if can have both y0 and y1 for each observation which is not true in real research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f37cec2",
   "metadata": {},
   "source": [
    "## Example of simple simulation\n",
    "\n",
    "We demonstrate with an artificial example of a randomized experiment on 100 students designed to\n",
    "test an intervention for improving final exam scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b901e3c5",
   "metadata": {},
   "source": [
    "### Simulating a randomized experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a8c893",
   "metadata": {},
   "source": [
    "We start by assigning the potential outcomes, the final exam scores that would be observed for each\n",
    "student if he or she gets the control or the treatment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1367cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "n = 100\n",
    "y_if_control = np.random.normal(60, 20, size=n)\n",
    "y_if_treated = y_if_control + 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135dc323",
   "metadata": {},
   "source": [
    "In this very simple model, the intervention would add 5 points to each student’s score.\n",
    "We then assign treatments (z = 0 for control or 1 for treatment), which then determine which\n",
    "outcome is observed for each person:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789fc667",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.random.binomial(1, 0.5, n)\n",
    "\n",
    "y = np.array([y0  if z == 0 else y1 for (y0, y1, z) in zip(y_if_control, y_if_treated, z)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d2e1d7",
   "metadata": {},
   "source": [
    "Having simulated the data, we can now compare treated to control outcomes and compute the standard\n",
    "error for the difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f3567",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = np.mean(y[z==1]) - np.mean(y[z==0])\n",
    "se_diff = np.sqrt(np.std(y[z==1]) ** 2 / len(y[z==1]) + np.std(y[z==0]) ** 2 / len(y[z==0]))\n",
    "\n",
    "print(diff, se_diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63be370e",
   "metadata": {},
   "source": [
    "Equivalently, we can run the regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21152b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['y'] = y\n",
    "data['z'] = z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1895c6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  smf.ols(formula=\"y ~ z\", \n",
    "                 data=data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519865d7",
   "metadata": {},
   "source": [
    "### Including a pre-treatment predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ea9099",
   "metadata": {},
   "source": [
    "Suppose we also have information about pre-test scores x. They have the same distribution as post-test scores y but with a slightly lower average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56d4db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['x'] = np.random.normal(50, 20, size=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e52bbf",
   "metadata": {},
   "source": [
    "We can then adjust for pre-test in our regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32a2aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  smf.ols(formula=\"y ~ z + x\", \n",
    "                 data=data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b1094f",
   "metadata": {},
   "source": [
    "Again, the coefficient of z estimates the treatment effect, and it still has a standard error of about\n",
    "4, which might seem surprising: shouldn’t the inclusion of a pre-treatment predictor increase the\n",
    "precision of our estimate? The answer is that, the way we constructed the pre-test variable, it wasn’t\n",
    "much of a pre-treatment predictor at all, as we simulated it independently of the potential outcomes\n",
    "for the final test score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d411e7bb",
   "metadata": {},
   "source": [
    "To perform a realistic simulation, we must simulate both test scores in a correlated way, which we\n",
    "do here by borrowing a trick from the example of simulated midterm and final exams:\n",
    "\n",
    "1. Each student is assumed to have a true ability drawn from a distribution with mean 50 and standard\n",
    "deviation 16.\n",
    "2. Each student’s score on the pre-test, x, is the sum of two components: the student’s true ability,\n",
    "and a random component with mean 0 and standard deviation 12, reflecting that performance on\n",
    "any given test will be unpredictable.\n",
    "3. Each student’s score on the post-test, y, is his or her true ability, plus another, independent, random\n",
    "component, plus an additional 10 points if a student receives the control or 15 points if he or she\n",
    "receives the treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67f88fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "\n",
    "n = 100\n",
    "true_ability = np.random.normal(50, 16, n)\n",
    "x = true_ability + np.random.normal(0, 12, n)\n",
    "y_if_control = true_ability + np.random.normal(0, 12, n)\n",
    "y_if_treated = y_if_control + 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2f0aea",
   "metadata": {},
   "source": [
    "As above, we assign treatments, construct the observed outcome, and put the data into a frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97911d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.random.binomial(1, 0.5, n)\n",
    "y = np.array([y0  if z == 0 else y1 for (y0, y1, z) in zip(y_if_control, y_if_treated, z)])\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data['y'] = y\n",
    "data['z'] = z\n",
    "data['x'] = x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada7f08b",
   "metadata": {},
   "source": [
    "The simple comparison is equivalent to a regression on the treatment indicator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b31f974",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  smf.ols(formula=\"y ~ z\", \n",
    "                 data=data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c207936",
   "metadata": {},
   "source": [
    "And the estimate adjusting for pre-test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb2f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  smf.ols(formula=\"y ~ z + x\", \n",
    "                 data=data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c76afe",
   "metadata": {},
   "source": [
    "In this case, with the strong dependence between pre-test and post-test, this adjustment has reduced\n",
    "the residual standard deviation by about a third."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2d9fc6",
   "metadata": {},
   "source": [
    "## Task for you\n",
    "\n",
    "(for better unserstanding, read the chapter 18 from Gelman book - https://users.aalto.fi/~ave/ROS.pdf)\n",
    "\n",
    "\n",
    "1. Simulate data from the table 18.5 from Gelman book (page 348)\n",
    "2. Try different treatment assignment:\n",
    "+ completely random treatment assignment\n",
    "+ block random experiment - \n",
    "Divide participants into 4 blocks by age: 40 years-old, 50 years-old, 60 years-old, 70-years old.\n",
    "In the first two blocks (Audrey through Brad) that contain the younger\n",
    "participants, the probability of receiving the supplements is 0.25 under this design, whereas in the\n",
    "last two blocks, with the older participants, this probability is 0.75.)\n",
    "\n",
    "3. Calculate SATE and CATE (for the same groups defined earlier) for both treatment assignment designs\n",
    "4. Using the first treatment assignment design, fit outcome regression for several draws, with and without covariates (sex, age).\n",
    "5. Describe results and the differences between the models (TE, standard errors). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
